import re
import unicodedata
from typing import Dict, List, Optional
from datetime import datetime, timedelta

class DataCleaner:
    def __init__(self):
        # åˆå§‹åŒ–åŒä¹‰è¯è¡¨
        self.synonym_dict = {
            'APP': 'åº”ç”¨',
            'app': 'åº”ç”¨',
            'å®¢æœå°å§å§': 'å®¢æœäººå‘˜',
            'é€€æ¢è´§': 'é€€è´§/æ¢è´§',
            'äº²': 'æ‚¨å¥½',
            'äº²äº²': 'æ‚¨å¥½'
        }
        
        # åˆå§‹åŒ–æ•æ„Ÿè¯åˆ—è¡¨
        self.forbidden_words = [
            "å‚»é€¼", "ä»–å¦ˆçš„", "æ“", "æ»š", "ç™½ç—´", "ç¬¨è›‹"
        ]
        
        # åˆå§‹åŒ–æµ‹è¯•å…³é”®è¯
        self.test_keywords = [
            "test", "æµ‹è¯•", "æµ‹è¯•æ•°æ®", "æµ‹è¯•ç”¨ä¾‹", "æµ‹è¯•ç¯å¢ƒ"
        ]
        
        # åˆå§‹åŒ–æ— æ•ˆå†…å®¹å…³é”®è¯
        self.invalid_keywords = [
            # ç³»ç»Ÿæ¶ˆæ¯å’Œæ ‡è®°
            "[å›¾ç‰‡]", "[è¡¨æƒ…]", "[è¯­éŸ³]", "[è§†é¢‘]", "[æ–‡ä»¶]",
            "[é“¾æ¥]", "[çº¢åŒ…]", "[è½¬è´¦]", "[ä½ç½®]", "[åç‰‡]",
            "[å°ç¨‹åº]", "[å…¬ä¼—å·]", "[ç¾¤èŠ]", "[ç§èŠ]", "[ç³»ç»Ÿ]",
            
            # è‡ªåŠ¨å›å¤å’Œæ¨¡æ¿æ¶ˆæ¯
            "æ‚¨å¥½ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡",
            "æ„Ÿè°¢æ‚¨çš„å’¨è¯¢",
            "æ­£åœ¨ä¸ºæ‚¨è½¬æ¥",
            "è¯·ç¨ç­‰",
            "æ­£åœ¨å¤„ç†ä¸­",
            "æ­£åœ¨ä¸ºæ‚¨æŸ¥è¯¢",
            "æ­£åœ¨ä¸ºæ‚¨æ ¸å®",
            "æ­£åœ¨ä¸ºæ‚¨å¤„ç†",
            "æ­£åœ¨ä¸ºæ‚¨åŠç†",
            "æ­£åœ¨ä¸ºæ‚¨å®¡æ ¸",
            
            # å¸¸è§æ— æ•ˆå†…å®¹
            "æ”¶åˆ°", "å¥½çš„", "å—¯", "å“¦", "å•Š", "å‘€", "å‘¢", "å§",
            "è°¢è°¢", "ä¸å®¢æ°”", "å†è§", "æ‹œæ‹œ", "æ™šå®‰", "æ—©å®‰",
            "åœ¨å—", "åœ¨çš„", "åœ¨çš„å“¦", "åœ¨çš„å‘¢", "åœ¨çš„å‘€",
            "è¯·ç¨ç­‰", "ç¨ç­‰", "ç­‰ç­‰", "ç­‰ä¸€ä¸‹", "ç¨ç­‰ç‰‡åˆ»",
            "æ­£åœ¨è¾“å…¥", "æ­£åœ¨è¾“å…¥ä¸­", "å¯¹æ–¹æ­£åœ¨è¾“å…¥",
            "å·²è¯»", "å·²é€è¾¾", "å·²å‘é€", "å‘é€æˆåŠŸ",
            "æ­£åœ¨åŠ è½½", "åŠ è½½ä¸­", "åŠ è½½å¤±è´¥", "åŠ è½½å®Œæˆ",
            
            # è¡¨æƒ…ç¬¦å·å’Œç‰¹æ®Šå­—ç¬¦
            "ğŸ˜Š", "ğŸ˜„", "ğŸ˜ƒ", "ğŸ˜€", "ğŸ˜", "ğŸ˜…", "ğŸ˜‚", "ğŸ¤£",
            "ğŸ‘", "ğŸ‘", "ğŸ‘Œ", "âœŒï¸", "ğŸ¤", "ğŸ™", "ğŸ’ª",
            "â¤ï¸", "ğŸ’•", "ğŸ’–", "ğŸ’—", "ğŸ’“", "ğŸ’", "ğŸ’",
            "ğŸŒŸ", "â­", "âœ¨", "ğŸ’«", "ğŸ’¥", "ğŸ’¦", "ğŸ’¨",
            
            # å¹¿å‘Šå’Œæ¨å¹¿
            "æ¨å¹¿", "å¹¿å‘Š", "ä¼˜æƒ ", "ä¿ƒé”€", "ç‰¹ä»·", "æŠ˜æ‰£",
            "é™æ—¶", "ç§’æ€", "æŠ¢è´­", "å›¢è´­", "æ‹¼å›¢", "ç ä»·",
            "æŠ½å¥–", "ä¸­å¥–", "å¥–å“", "ç¤¼å“", "èµ å“", "ç¤¼åŒ…",
            
            # ç³»ç»Ÿæç¤ºå’ŒçŠ¶æ€
            "ç³»ç»Ÿç»´æŠ¤ä¸­", "ç³»ç»Ÿå‡çº§ä¸­", "ç³»ç»Ÿæ›´æ–°ä¸­",
            "ç½‘ç»œè¿æ¥ä¸­", "æ­£åœ¨è¿æ¥", "è¿æ¥å¤±è´¥",
            "æ­£åœ¨åŒæ­¥", "åŒæ­¥å®Œæˆ", "åŒæ­¥å¤±è´¥",
            "æ­£åœ¨ä¸‹è½½", "ä¸‹è½½å®Œæˆ", "ä¸‹è½½å¤±è´¥",
            "æ­£åœ¨ä¸Šä¼ ", "ä¸Šä¼ å®Œæˆ", "ä¸Šä¼ å¤±è´¥",
            
            # å…¶ä»–æ— æ•ˆå†…å®¹
            "ç‚¹å‡»æŸ¥çœ‹", "æŸ¥çœ‹æ›´å¤š", "æŸ¥çœ‹è¯¦æƒ…",
            "å¤åˆ¶æˆåŠŸ", "å¤åˆ¶å¤±è´¥", "å¤åˆ¶é“¾æ¥",
            "åˆ†äº«æˆåŠŸ", "åˆ†äº«å¤±è´¥", "åˆ†äº«é“¾æ¥",
            "è½¬å‘æˆåŠŸ", "è½¬å‘å¤±è´¥", "è½¬å‘é“¾æ¥",
            "ä¿å­˜æˆåŠŸ", "ä¿å­˜å¤±è´¥", "ä¿å­˜å›¾ç‰‡",
            "åˆ é™¤æˆåŠŸ", "åˆ é™¤å¤±è´¥", "åˆ é™¤æ¶ˆæ¯",
            "æ’¤å›æˆåŠŸ", "æ’¤å›å¤±è´¥", "æ’¤å›æ¶ˆæ¯",
            "æ¸…ç©ºæˆåŠŸ", "æ¸…ç©ºå¤±è´¥", "æ¸…ç©ºèŠå¤©",
            "ç½®é¡¶æˆåŠŸ", "ç½®é¡¶å¤±è´¥", "å–æ¶ˆç½®é¡¶",
            "å…æ‰“æ‰°", "æ¶ˆæ¯å…æ‰“æ‰°", "ç¾¤èŠå…æ‰“æ‰°",
            "å·²é™éŸ³", "å·²å±è”½", "å·²æ‹‰é»‘", "å·²ä¸¾æŠ¥",
            "å·²å…³æ³¨", "å·²å–æ¶ˆå…³æ³¨", "å·²ç‚¹èµ", "å·²æ”¶è—"
        ]

    def standardize_encoding(self, text: str) -> str:
        """ç»Ÿä¸€ç¼–ç æ ¼å¼"""
        if not isinstance(text, str):
            return str(text)
        return unicodedata.normalize('NFKC', text)

    def standardize_datetime(self, dt: datetime) -> datetime:
        """æ ‡å‡†åŒ–æ—¥æœŸæ—¶é—´æ ¼å¼"""
        if not isinstance(dt, datetime):
            return dt
        return dt.replace(microsecond=0)

    def clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬å†…å®¹"""
        if not isinstance(text, str):
            return str(text)
        
        # 1. ç»Ÿä¸€ç¼–ç 
        text = self.standardize_encoding(text)
        
        # 2. åˆ é™¤ç³»ç»Ÿæ ‡è®°å’Œç‰¹æ®Šå­—ç¬¦
        text = re.sub(r'\[.*?\]', '', text)  # åˆ é™¤æ–¹æ‹¬å·å†…å®¹
        text = re.sub(r'ã€.*?ã€‘', '', text)  # åˆ é™¤ä¸­æ–‡æ–¹æ‹¬å·å†…å®¹
        text = re.sub(r'<.*?>', '', text)   # åˆ é™¤HTMLæ ‡ç­¾
        
        # 3. åˆ é™¤é“¾æ¥
        text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)  # åˆ é™¤httpé“¾æ¥
        text = re.sub(r'www\.(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)  # åˆ é™¤wwwé“¾æ¥
        text = re.sub(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', '', text)  # åˆ é™¤é‚®ç®±é“¾æ¥
        text = re.sub(r'[a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*\.[a-zA-Z]{2,}', '', text)  # åˆ é™¤åŸŸå
        text = re.sub(r'[a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*\.(?:com|cn|net|org|edu|gov|mil|biz|info|name|mobi|asia|app|dev|io|co|me|tv|cc|xyz|top|site|online|tech|store|blog|shop|club|fun|game|live|news|video|music|photo|cloud|host|link|network|services|solutions|agency|studio|design|digital|media|marketing|agency|consulting|group|inc|ltd|llc|corp|company|business|enterprise|solutions|services|agency|studio|design|digital|media|marketing|agency|consulting|group|inc|ltd|llc|corp|company|business|enterprise)', '', text)  # åˆ é™¤å¸¸è§åŸŸååç¼€
        
        # 4. åªä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—å’ŒåŸºæœ¬æ ‡ç‚¹
        text = re.sub(r'[^\w\s\u4e00-\u9fffï¼Œã€‚ï¼ï¼Ÿã€ï¼šï¼›""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹]', '', text)
        
        # 5. åˆ é™¤é‡å¤å­—ç¬¦å’Œå¤šä½™ç©ºæ ¼
        text = re.sub(r'(.)\1{2,}', r'\1\1', text)  # ç¼©å‡é‡å¤å­—ç¬¦
        text = re.sub(r'\s+', ' ', text)  # åˆå¹¶å¤šä¸ªç©ºæ ¼
        
        # 6. æ›¿æ¢åŒä¹‰è¯å’Œæ ‡å‡†åŒ–ç”¨è¯­
        for old, new in self.synonym_dict.items():
            text = text.replace(old, new)
        
        # 7. è„±æ•å¤„ç†
        text = re.sub(r'(1[3-9]\d{9})', '*******\g<1>[-4:]', text)  # æ‰‹æœºå·
        text = re.sub(r'(\d{17}[\dXx])', 'ID_\g<1>[-4:]', text)  # èº«ä»½è¯å·
        text = re.sub(r'(\d{16})', 'CARD_\g<1>[-4:]', text)  # é“¶è¡Œå¡å·
        
        # 8. åˆ é™¤æ— æ•ˆå†…å®¹
        for keyword in self.invalid_keywords:
            text = text.replace(keyword, '')
            
        # 9. åˆ é™¤è¿‡çŸ­çš„å¥å­å’Œæ— æ„ä¹‰å†…å®¹
        text = re.sub(r'^[\s\.,ï¼Œã€‚!ï¼?ï¼Ÿ]+$', '', text)  # åˆ é™¤åªæœ‰æ ‡ç‚¹çš„å¥å­
        text = re.sub(r'^[a-zA-Z0-9\s]+$', '', text)  # åˆ é™¤çº¯è‹±æ–‡æ•°å­—çš„å¥å­
        
        # 10. æ ‡å‡†åŒ–æ ‡ç‚¹ç¬¦å·
        text = text.replace('ï¼Œ', ',')
        text = text.replace('ã€‚', '.')
        text = text.replace('ï¼', '!')
        text = text.replace('ï¼Ÿ', '?')
        text = text.replace('ï¼š', ':')
        text = text.replace('ï¼›', ';')
        
        # 11. åˆ é™¤å¤šä½™çš„ç©ºæ ¼å’Œæ¢è¡Œ
        text = re.sub(r'\n+', ' ', text)  # å°†æ¢è¡Œæ›¿æ¢ä¸ºç©ºæ ¼
        text = re.sub(r'\s+', ' ', text)  # åˆå¹¶å¤šä¸ªç©ºæ ¼
        text = text.strip()  # åˆ é™¤é¦–å°¾ç©ºæ ¼
        
        return text

    def is_valid_message(self, text: str) -> bool:
        """åˆ¤æ–­æ¶ˆæ¯æ˜¯å¦æœ‰æ•ˆ"""
        if not isinstance(text, str):
            return False
            
        # 1. æ£€æŸ¥é•¿åº¦
        if len(text.strip()) < 3:
            return False
            
        # 2. æ£€æŸ¥æ˜¯å¦åŒ…å«æµ‹è¯•å…³é”®è¯
        if any(keyword in text.lower() for keyword in self.test_keywords):
            return False
            
        # 3. æ£€æŸ¥æ˜¯å¦åŒ…å«æ•æ„Ÿè¯
        if any(word in text for word in self.forbidden_words):
            return False
            
        # 4. æ£€æŸ¥æ˜¯å¦åªåŒ…å«æ ‡ç‚¹ç¬¦å·
        if re.match(r'^[\s\.,ï¼Œã€‚!ï¼?ï¼Ÿ]+$', text):
            return False
            
        # 5. æ£€æŸ¥æ˜¯å¦åªåŒ…å«è‹±æ–‡æ•°å­—
        if re.match(r'^[a-zA-Z0-9\s]+$', text):
            return False
            
        # 6. æ£€æŸ¥æ˜¯å¦åŒ…å«ç³»ç»Ÿæ¶ˆæ¯ç‰¹å¾
        if re.search(r'ç³»ç»Ÿ|æç¤º|é€šçŸ¥|å…¬å‘Š|æ¶ˆæ¯|æé†’', text):
            return False
            
        # 7. æ£€æŸ¥æ˜¯å¦åŒ…å«è‡ªåŠ¨å›å¤ç‰¹å¾
        if re.search(r'æ‚¨å¥½|æ„Ÿè°¢|è°¢è°¢|å†è§|æ¬¢è¿|å®¢æœ', text) and len(text) < 10:
            return False
            
        return True

    def extract_tags(self, text: str) -> List[str]:
        """æå–æ–‡æœ¬æ ‡ç­¾"""
        tags = []
        
        # å®šä¹‰æ ‡ç­¾è§„åˆ™
        tag_rules = {
            'æ”¯ä»˜é—®é¢˜': r'æ”¯ä»˜|ä»˜æ¬¾|é€€æ¬¾|è½¬è´¦|ä½™é¢|è´¹ç”¨|æ”¶è´¹|ä»·æ ¼|é‡‘é¢|æ”¯ä»˜æ–¹å¼|æ”¯ä»˜å®|å¾®ä¿¡æ”¯ä»˜',
            'ç‰©æµé—®é¢˜': r'å¿«é€’|ç‰©æµ|é…é€|å‘è´§|æ”¶è´§|è¿è¾“|é€è¾¾|æ´¾é€|åŒ…è£¹|å¿«é€’è´¹|è¿è´¹',
            'è´¦æˆ·é—®é¢˜': r'ç™»å½•|æ³¨å†Œ|å¯†ç |è´¦å·|è®¤è¯|å®å|èº«ä»½|ç»‘å®š|è§£ç»‘|æ³¨é”€|æŒ‚å¤±|æ‰¾å›',
            'å•†å“é—®é¢˜': r'å•†å“|äº§å“|ä»·æ ¼|è´¨é‡|è§„æ ¼|å‹å·|å“ç‰Œ|åº“å­˜|ç¼ºè´§|æ–­è´§|ä¸‹æ¶|ä¸Šæ¶',
            'è®¢å•é—®é¢˜': r'è®¢å•|ä¸‹å•|å–æ¶ˆ|ä¿®æ”¹|æŸ¥è¯¢|è·Ÿè¸ª|çŠ¶æ€|è¿›åº¦|ç¡®è®¤|å–æ¶ˆ|é€€æ¬¾|é€€è´§',
            'æœåŠ¡é—®é¢˜': r'æœåŠ¡|å®¢æœ|å”®å|ç»´ä¿®|ä¿ä¿®|ä¿å…»|å®‰è£…|è°ƒè¯•|åŸ¹è®­|æŒ‡å¯¼|å’¨è¯¢',
            'ç³»ç»Ÿé—®é¢˜': r'ç³»ç»Ÿ|è½¯ä»¶|ç¨‹åº|åº”ç”¨|APP|ç½‘é¡µ|ç½‘ç«™|ç½‘ç»œ|è¿æ¥|å¡é¡¿|å´©æºƒ|é”™è¯¯',
            'å®‰å…¨éšç§': r'å®‰å…¨|éšç§|ä¿æŠ¤|æ³„éœ²|åŠ å¯†|è§£å¯†|æˆæƒ|æƒé™|éªŒè¯|è®¤è¯|å®å',
            'ä¼˜æƒ æ´»åŠ¨': r'ä¼˜æƒ |æ´»åŠ¨|ä¿ƒé”€|æŠ˜æ‰£|æ»¡å‡|åˆ¸|çº¢åŒ…|ç§¯åˆ†|ä¼šå‘˜|VIP|ç‰¹æƒ',
            'æŠ•è¯‰å»ºè®®': r'æŠ•è¯‰|å»ºè®®|åé¦ˆ|æ„è§|ä¸¾æŠ¥|ç»´æƒ|çº çº·|äº‰è®®|é—®é¢˜|ä¸æ»¡|å·®è¯„'
        }
        
        # è½¬æ¢ä¸ºå°å†™ä»¥è¿›è¡Œä¸åŒºåˆ†å¤§å°å†™çš„åŒ¹é…
        text = text.lower()
        
        for tag, pattern in tag_rules.items():
            if re.search(pattern, text):
                tags.append(tag)
        
        # æ·»åŠ ç‰¹æ®Šæ ‡ç­¾
        if re.search(r'etc|é«˜é€Ÿå…¬è·¯|é€šè¡Œè´¹|æ”¶è´¹ç«™|etcå¡|etcè®¾å¤‡', text):
            tags.append('ETCä¸šåŠ¡')
            
        if re.search(r'è½¦ç‰Œ|è½¦è¾†|æ±½è½¦|é©¾ç…§|é©¾é©¶è¯|è¡Œé©¶è¯|è¿ç« |å¹´æ£€|ä¿é™©', text):
            tags.append('è½¦è¾†ç›¸å…³')
            
        if re.search(r'å‘ç¥¨|ç¥¨æ®|æ”¶æ®|æŠ¥é”€|å‡­è¯|å•æ®', text):
            tags.append('ç¥¨æ®é—®é¢˜')
            
        if re.search(r'ç´§æ€¥|æ€¥|å¿«|ç«‹å³|é©¬ä¸Š|å°½å¿«|åŠ æ€¥|åŠ æ€¥å¤„ç†', text):
            tags.append('ç´§æ€¥é—®é¢˜')
            
        # å»é‡
        return list(set(tags))

    def is_new_session(self, current_time: datetime, last_time: datetime, 
                      timeout_minutes: int = 30) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ–°ä¼šè¯"""
        if not isinstance(current_time, datetime) or not isinstance(last_time, datetime):
            return True
        time_diff = (current_time - last_time).total_seconds() / 60
        return time_diff > timeout_minutes 